{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#from sklearn.metrics import classification_report\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "\n",
    "#from sklearn.base import TransformerMixin\n",
    "#class DenseTransformer(TransformerMixin):\n",
    "#    \n",
    "#    def fit(self, X, y=None, **fit_params):\n",
    "#        return self\n",
    "#    \n",
    "#    def transform(self, X, y=None, **fit_params):\n",
    "#        return X.todense()\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.linear_model import LogisticRegressionCV\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Eric/Documents/DataAnalyticsBootcamp/MY_WORK_AREA/UTAUS201901DATA3/Projects/FinalProject/repo_world_wine_web_MY_SANDBOX/FinalProject-WorldWineWebML/ml_models\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>points</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>87</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>87</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>87</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>87</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Blackberry and raspberry aromas show a typical...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>87</td>\n",
       "      <td>Tempranillo-Merlot</td>\n",
       "      <td>Tandem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   country                                        description  \\\n",
       "0           1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
       "1           2        US  Tart and snappy, the flavors of lime flesh and...   \n",
       "2           3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
       "3           4        US  Much like the regular bottling from 2012, this...   \n",
       "4           5     Spain  Blackberry and raspberry aromas show a typical...   \n",
       "\n",
       "   price  points             variety               winery  \n",
       "0   15.0      87      Portuguese Red  Quinta dos Avidagos  \n",
       "1   14.0      87          Pinot Gris            Rainstorm  \n",
       "2   13.0      87            Riesling           St. Julian  \n",
       "3   65.0      87          Pinot Noir         Sweet Cheeks  \n",
       "4   15.0      87  Tempranillo-Merlot               Tandem  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the data\n",
    "data = pd.read_csv(\"final_wine_data_172k_test.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Blackberry and raspberry aromas show a typical...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description\n",
       "0  Portugal  This is ripe and fruity, a wine that is smooth...\n",
       "1        US  Tart and snappy, the flavors of lime flesh and...\n",
       "2        US  Pineapple rind, lemon pith and orange blossom ...\n",
       "3        US  Much like the regular bottling from 2012, this...\n",
       "4     Spain  Blackberry and raspberry aromas show a typical..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter just the country and descirption fields\n",
    "data = data.filter([\"country\", \"description\"], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Portugal', 'US', 'Spain', 'Italy', 'France', 'Germany',\n",
       "       'Argentina', 'Chile', 'Australia', 'Austria', 'South Africa',\n",
       "       'New Zealand', 'Israel', 'Hungary', 'Greece', 'Romania', 'Mexico',\n",
       "       'Canada', 'Turkey', 'Czech Republic', 'Slovenia', 'Luxembourg',\n",
       "       'Croatia', 'Georgia', 'Uruguay', 'England', 'Lebanon', 'Serbia',\n",
       "       'Brazil', 'Moldova', 'Morocco', 'Peru', 'India', 'Bulgaria',\n",
       "       'Cyprus', 'Armenia', 'Switzerland', 'Bosnia and Herzegovina',\n",
       "       'Ukraine', 'Slovakia', 'Macedonia', 'China', 'Kosovo', 'Global'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at the unique countries\n",
    "data['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US                        70956\n",
       "Italy                     31757\n",
       "France                    26183\n",
       "Spain                      8609\n",
       "Portugal                   6913\n",
       "Chile                      5284\n",
       "Argentina                  4567\n",
       "Austria                    3866\n",
       "Australia                  3148\n",
       "Germany                    2917\n",
       "New Zealand                1935\n",
       "South Africa               1582\n",
       "Israel                      689\n",
       "Greece                      566\n",
       "Canada                      336\n",
       "Uruguay                     228\n",
       "Bulgaria                    202\n",
       "Hungary                     187\n",
       "Romania                     143\n",
       "England                     123\n",
       "Georgia                     113\n",
       "Turkey                      107\n",
       "Moldova                     100\n",
       "Croatia                      85\n",
       "Slovenia                     84\n",
       "Brazil                       73\n",
       "Mexico                       73\n",
       "Lebanon                      35\n",
       "Morocco                      34\n",
       "Switzerland                  20\n",
       "Peru                         17\n",
       "Ukraine                      17\n",
       "Luxembourg                   16\n",
       "Kosovo                       16\n",
       "Czech Republic               14\n",
       "Serbia                       12\n",
       "Macedonia                    12\n",
       "Cyprus                       12\n",
       "India                         9\n",
       "Armenia                       7\n",
       "China                         6\n",
       "Bosnia and Herzegovina        3\n",
       "Global                        2\n",
       "Slovakia                      1\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at the country balance\n",
    "data['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Blackberry and raspberry aromas show a typical...</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description  length\n",
       "0  Portugal  This is ripe and fruity, a wine that is smooth...     227\n",
       "1        US  Tart and snappy, the flavors of lime flesh and...     186\n",
       "2        US  Pineapple rind, lemon pith and orange blossom ...     199\n",
       "3        US  Much like the regular bottling from 2012, this...     249\n",
       "4     Spain  Blackberry and raspberry aromas show a typical...     261"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#peek at the description length\n",
    "data['length'] = data['description'].apply(lambda x: len(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country        object\n",
       "description    object\n",
       "length          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at the data types\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US          70956\n",
       "Italy       31757\n",
       "France      26183\n",
       "Spain        8609\n",
       "Portugal     6913\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use Counter to get the top 20 wine countries\n",
    "\n",
    "counter = Counter(data['country'].tolist())\n",
    "top_5_countries = {i[0]: idx for idx, i in enumerate(counter.most_common(5))}\n",
    "top5_countries_data = data[data['country'].map(lambda x: x in top_5_countries)]\n",
    "\n",
    "top5_countries_data['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Blackberry and raspberry aromas show a typical...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description\n",
       "0  Portugal  This is ripe and fruity, a wine that is smooth...\n",
       "1        US  Tart and snappy, the flavors of lime flesh and...\n",
       "2        US  Pineapple rind, lemon pith and orange blossom ...\n",
       "3        US  Much like the regular bottling from 2012, this...\n",
       "4     Spain  Blackberry and raspberry aromas show a typical..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out all extraneaous columns\n",
    "df = top5_countries_data.filter([\"country\", \"description\"], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Blackberry and raspberry aromas show a typical...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description\n",
       "0  Portugal  This is ripe and fruity, a wine that is smooth...\n",
       "1        US  Tart and snappy, the flavors of lime flesh and...\n",
       "2        US  Pineapple rind, lemon pith and orange blossom ...\n",
       "3        US  Much like the regular bottling from 2012, this...\n",
       "4     Spain  Blackberry and raspberry aromas show a typical..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data['description']\n",
    "y=data['country']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7716728984905138 \n",
      "\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "     France       0.87      0.47      0.98      0.61      0.68      0.44      5238\n",
      "      Italy       0.73      0.98      0.90      0.84      0.94      0.89      6204\n",
      "   Portugal       0.34      0.78      0.92      0.48      0.85      0.71      1414\n",
      "      Spain       0.57      0.99      0.95      0.72      0.97      0.94      1777\n",
      "         US       0.96      0.76      0.97      0.85      0.86      0.72     14251\n",
      "\n",
      "avg / total       0.84      0.77      0.95      0.78      0.85      0.72     28884\n",
      "\n",
      "CPU times: user 44.2 s, sys: 9.04 s, total: 53.3 s\n",
      "Wall time: 43.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "naive_bayes = make_pipeline_imb(\n",
    "    CountVectorizer(stop_words='english', binary=True),\n",
    "    NearMiss(),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {naive_bayes.score(X_test, y_test)} \\n')\n",
    "print(classification_report_imbalanced(y_test, naive_bayes.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8952361168813183 \n",
      "\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "     France       0.87      0.79      0.97      0.83      0.88      0.76      5238\n",
      "      Italy       1.00      0.83      1.00      0.91      0.91      0.82      6204\n",
      "   Portugal       0.67      0.67      0.98      0.67      0.81      0.64      1414\n",
      "      Spain       0.89      0.92      0.99      0.91      0.96      0.91      1777\n",
      "         US       0.89      0.98      0.88      0.93      0.93      0.87     14251\n",
      "\n",
      "avg / total       0.90      0.90      0.93      0.89      0.91      0.83     28884\n",
      "\n",
      "CPU times: user 4min 39s, sys: 19.7 s, total: 4min 59s\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "naive_bayes = make_pipeline_imb(\n",
    "    CountVectorizer(stop_words='english', binary=True),\n",
    "    SMOTE(),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {naive_bayes.score(X_test, y_test)} \\n')\n",
    "print(classification_report_imbalanced(y_test, naive_bayes.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### didnt wait--Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "gaussian_naive_bayes = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    TfidfTransformer(),\n",
    "    DenseTransformer(),    \n",
    "    GaussianNB()\n",
    ")\n",
    "\n",
    "gaussian_naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {gaussian_naive_bayes.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, gaussian_naive_bayes.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Bigram Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bigram_naive_bayes = make_pipeline_imb(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        binary=True,\n",
    "        ngram_range=(1, 2)\n",
    "    ),\n",
    "    NearMiss(),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "bigram_naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {bigram_naive_bayes.score(X_test, y_test)} \\n')\n",
    "print(classification_report_imbalanced(y_test, bigram_naive_bayes.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Normalizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Normalizer' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "normalized_lr = make_pipeline_imb(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    Normalizer(),\n",
    "    NearMiss(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "normalized_lr.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {normalized_lr.score(X_test, y_test)} \\n')\n",
    "print(classification_report_imbalanced(y_test, normalized_lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Eric/anaconda3/envs/ut_ml/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/Eric/anaconda3/envs/ut_ml/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8511632737847944 \n",
      "\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "     France       0.90      0.52      0.99      0.66      0.72      0.49      5238\n",
      "      Italy       0.90      0.96      0.97      0.93      0.97      0.93      6204\n",
      "   Portugal       0.47      0.76      0.96      0.58      0.86      0.72      1414\n",
      "      Spain       0.65      0.97      0.97      0.78      0.97      0.94      1777\n",
      "         US       0.92      0.92      0.92      0.92      0.92      0.84     14251\n",
      "\n",
      "avg / total       0.87      0.85      0.95      0.85      0.89      0.80     28884\n",
      "\n",
      "CPU times: user 47.4 s, sys: 8.54 s, total: 56 s\n",
      "Wall time: 42.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TF-IDF Logistic Regression Model\n",
    "\n",
    "tfidf_logistic_regression = make_pipeline_imb(\n",
    "   CountVectorizer(strip_accents='ascii',\n",
    "                   stop_words='english'),\n",
    "   TfidfTransformer(),\n",
    "    NearMiss(),\n",
    "   LogisticRegression(),\n",
    "   \n",
    "   \n",
    ")\n",
    "\n",
    "tfidf_logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_logistic_regression.score(X_test, y_test)} \\n')\n",
    "print(classification_report_imbalanced(y_test, tfidf_logistic_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Word Count Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "normalized_lr = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    Normalizer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "normalized_lr.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {normalized_lr.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, normalized_lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram TF-IDF Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bigram_tfidf_logistic_regression = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        ngram_range=(1,2)\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "bigram_tfidf_logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {bigram_tfidf_logistic_regression.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, bigram_tfidf_logistic_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TF-IDF Logistic Regression with Automatic Corpus Specific Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mindf_max_tfidf_lr = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        min_df=2,\n",
    "        max_df=.9\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "mindf_max_tfidf_lr.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {mindf_max_tfidf_lr.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, mindf_max_tfidf_lr.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### caused reboot-Linear Discrete Analysis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "tfidf_lda = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    DenseTransformer(),\n",
    "    LinearDiscriminantAnalysis()\n",
    ")\n",
    "\n",
    "tfidf_lda.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_lda.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_lda.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_svc = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        #min_df = 2,      # ed\n",
    "        #max_df = .2      # ed\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    #DenseTransformer(),\n",
    "    LinearSVC()\n",
    ")\n",
    "\n",
    "tfidf_svc.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_svc.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### warnings--dnf   TF-IDF Logistic Lasso"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "tfidf_logistic_regression_lasso = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegressionCV(\n",
    "        penalty='l1',\n",
    "        solver='saga' \n",
    "    )\n",
    ")\n",
    "\n",
    "tfidf_logistic_regression_lasso.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_logistic_regression_lasso.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_logistic_regression_lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coef do not converge -- TF-IDF Logistic Ridge"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "tfidf_logistic_regression_ridge = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegressionCV(\n",
    "        penalty='l2',\n",
    "        solver='saga' \n",
    "    )\n",
    ")\n",
    "\n",
    "tfidf_logistic_regression_ridge.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_logistic_regression_ridge.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_logistic_regression_ridge.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### error-TF-IDF Logistic Elasticnet"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "tfidf_logistic_regression_elasticnet = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegressionCV(\n",
    "        penalty='elasticnet',\n",
    "        l1_ratios=[0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1],\n",
    "        solver='saga' \n",
    "    )\n",
    ")\n",
    "\n",
    "tfidf_logistic_regression_elasticnet.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_logistic_regression_elasticnet.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_logistic_regression_elasticnet.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Top 20 Countries with top 3 accurate Models from above full data set work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Counter to get the top 20 wine countries\n",
    "\n",
    "counter = Counter(data['country'].tolist())\n",
    "top_20_countries = {i[0]: idx for idx, i in enumerate(counter.most_common(20))}\n",
    "top20_countries_data = data[data['country'].map(lambda x: x in top_20_countries)]\n",
    "\n",
    "top20_countries_data['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out all extraneaous columns\n",
    "\n",
    "df = top20_countries_data.filter([\"country\", \"description\"], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing datasets\n",
    "\n",
    "X=df['description']\n",
    "y=df['country']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logistic Regression Model:  Pvs Accuracy: 0.8575353677072373  <<<<<<<<  #3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# TF-IDF Logistic Regression Model\n",
    "\n",
    "tfidf_logistic_regression = make_pipeline(\n",
    "   CountVectorizer(strip_accents='ascii',\n",
    "                   stop_words='english'),\n",
    "   TfidfTransformer(),\n",
    "   LogisticRegression(),\n",
    "      \n",
    ")\n",
    "\n",
    "tfidf_logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_logistic_regression.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_logistic_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TF-IDF Logistic Regression with Automatic Corpus Specific Stop Words:  Pvs Accuracy: 0.8578861218285981   <<<<<<<  #2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mindf_max_tfidf_lr = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        min_df=2,\n",
    "        max_df=.9\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "mindf_max_tfidf_lr.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {mindf_max_tfidf_lr.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, mindf_max_tfidf_lr.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Linear SVC:  Pvs  Accuracy: 0.881942008651935     <<<<<   #1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_svc = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words='english',\n",
    "        #min_df = 2,      # ed\n",
    "        #max_df = .2      # ed\n",
    "    ),\n",
    "    TfidfTransformer(),\n",
    "    #DenseTransformer(),\n",
    "    LinearSVC()\n",
    ")\n",
    "\n",
    "tfidf_svc.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy: {tfidf_svc.score(X_test, y_test)} \\n')\n",
    "print(classification_report(y_test, tfidf_svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Use SMOTE oversampling\n",
    "smote_pipeline = make_pipeline_imb(SMOTE(random_state=42), classifier(random_state=42))\n",
    "smote_model = smote_pipeline.fit(X_train, y_train)\n",
    "smote_prediction = smote_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ut_ml",
   "language": "python",
   "name": "ut_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
