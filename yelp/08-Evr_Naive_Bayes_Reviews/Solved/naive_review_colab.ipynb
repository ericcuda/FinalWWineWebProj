{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naive_review_colab.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FQL3Zm0KPpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.3-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS9tTt7UKQem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"activity_8\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E46kq7cFKNMp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "8cce3d9f-a87b-4486-a805-a6c22109fb6d"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://s3.amazonaws.com/dataviz-curriculum/day_2/yelp_reviews.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"yelp_reviews.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+\n",
            "|   class|                text|\n",
            "+--------+--------------------+\n",
            "|positive|Wow... Loved this...|\n",
            "|negative|  Crust is not good.|\n",
            "|negative|Not tasty and the...|\n",
            "|positive|Stopped by during...|\n",
            "|positive|The selection on ...|\n",
            "|negative|Now I am getting ...|\n",
            "|negative|Honeslty it didn'...|\n",
            "|negative|The potatoes were...|\n",
            "|positive|The fries were gr...|\n",
            "|positive|      A great touch.|\n",
            "|positive|Service was very ...|\n",
            "|negative|  Would not go back.|\n",
            "|negative|The cashier had n...|\n",
            "|positive|I tried the Cape ...|\n",
            "|negative|I was disgusted b...|\n",
            "|negative|I was shocked bec...|\n",
            "|positive| Highly recommended.|\n",
            "|negative|Waitress was a li...|\n",
            "|negative|This place is not...|\n",
            "|negative|did not like at all.|\n",
            "+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_ejg07LKNMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "a850e2c7-39c2-464e-f277-80fe563b0a51"
      },
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature \n",
        "data_df = df.withColumn('length', length(df['text']))\n",
        "data_df.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+------+\n",
            "|   class|                text|length|\n",
            "+--------+--------------------+------+\n",
            "|positive|Wow... Loved this...|    24|\n",
            "|negative|  Crust is not good.|    18|\n",
            "|negative|Not tasty and the...|    41|\n",
            "|positive|Stopped by during...|    87|\n",
            "|positive|The selection on ...|    59|\n",
            "|negative|Now I am getting ...|    46|\n",
            "|negative|Honeslty it didn'...|    37|\n",
            "|negative|The potatoes were...|   111|\n",
            "|positive|The fries were gr...|    25|\n",
            "|positive|      A great touch.|    14|\n",
            "|positive|Service was very ...|    24|\n",
            "|negative|  Would not go back.|    18|\n",
            "|negative|The cashier had n...|    99|\n",
            "|positive|I tried the Cape ...|    59|\n",
            "|negative|I was disgusted b...|    62|\n",
            "|negative|I was shocked bec...|    50|\n",
            "|positive| Highly recommended.|    19|\n",
            "|negative|Waitress was a li...|    38|\n",
            "|negative|This place is not...|    51|\n",
            "|negative|did not like at all.|    20|\n",
            "+--------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph2OnGe5KNMv",
        "colab_type": "text"
      },
      "source": [
        "### Feature Transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT2XZfe8KNMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "# Create all the features to the data set\n",
        "pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "hashingTF = HashingTF(inputCol=\"token_text\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17tXmqkgKNMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOwrwVFxKNM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lvuaNxSKNM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(data_df)\n",
        "cleaned = cleaner.transform(data_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_y6KA9HKNM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "3e5dbfb0-af04-470f-d298-7d2d9b9db2d0"
      },
      "source": [
        "# Show label and resulting features\n",
        "cleaned.select(['label', 'features']).show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  0.0|(262145,[33933,69...|\n",
            "|  1.0|(262145,[15889,13...|\n",
            "|  1.0|(262145,[25570,63...|\n",
            "|  0.0|(262145,[6286,272...|\n",
            "|  0.0|(262145,[6979,255...|\n",
            "|  1.0|(262145,[24417,24...|\n",
            "|  1.0|(262145,[12084,48...|\n",
            "|  1.0|(262145,[3645,963...|\n",
            "|  0.0|(262145,[53777,10...|\n",
            "|  0.0|(262145,[138356,2...|\n",
            "|  0.0|(262145,[24113,25...|\n",
            "|  1.0|(262145,[68867,13...|\n",
            "|  1.0|(262145,[24417,36...|\n",
            "|  0.0|(262145,[18098,24...|\n",
            "|  1.0|(262145,[24417,25...|\n",
            "|  1.0|(262145,[24417,25...|\n",
            "|  0.0|(262145,[31704,21...|\n",
            "|  1.0|(262145,[25570,27...|\n",
            "|  1.0|(262145,[12329,15...|\n",
            "|  1.0|(262145,[8287,139...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO-SXuUdKNM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGovCyH9KNM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "b00a58ae-8e21-472f-a628-8993a78c96e3"
      },
      "source": [
        "# Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|   class|                text|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|negative|\"It was extremely...|    51|  1.0|[\"it, was, extrem...|[\"it, extremely, ...|(262144,[7388,255...|(262144,[7388,255...|(262145,[7388,255...|[-483.55575551650...|[0.01885080752039...|       1.0|\n",
            "|negative|After waiting an ...|    75|  1.0|[after, waiting, ...|[waiting, hour, s...|(262144,[9639,175...|(262144,[9639,175...|(262145,[9639,175...|[-792.86275832491...|[2.27409595856612...|       1.0|\n",
            "|negative|Also, I feel like...|    58|  1.0|[also,, i, feel, ...|[also,, feel, lik...|(262144,[24417,61...|(262144,[24417,61...|(262145,[24417,61...|[-600.31082538975...|[9.40386803566252...|       1.0|\n",
            "|negative|Also, the fries a...|    66|  1.0|[also,, the, frie...|[also,, fries, wi...|(262144,[90839,10...|(262144,[90839,10...|(262145,[90839,10...|[-735.81234077083...|[4.48680727123481...|       1.0|\n",
            "|negative|And the red curry...|    72|  1.0|[and, the, red, c...|[red, curry, much...|(262144,[56407,76...|(262144,[56407,76...|(262145,[56407,76...|[-805.26322202580...|[4.16570885587460...|       1.0|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Pj1bepEKNNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2860a56-29ce-4bf1-9aa4-ed127f672a09"
      },
      "source": [
        "# Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.767810\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hygCwnVLKnqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}